{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKl5RQYl1-MH"
      },
      "source": [
        "## Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e91gqBcDAF7q"
      },
      "source": [
        "#connect to google sheets\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "#google translate\n",
        "!pip install googletrans\n",
        "from googletrans import Translator\n",
        "tr = Translator()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# !pip install requests\n",
        "# !pip install beautifulsoup4\n",
        "\n",
        "import requests\n",
        "import urllib.request\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#parallel processing\n",
        "!pip install pandarallel\n",
        "from pandarallel import pandarallel\n",
        "pandarallel.initialize()\n",
        "\n",
        "import timeit\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wI-0_v4phJZ"
      },
      "source": [
        "# Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HncSNOi9sRnK"
      },
      "source": [
        "# @markdown This cell connects to the output sheet\n",
        "\n",
        "output_url = 'https://docs.google.com/spreadsheets/d/1pYvN_TTqxG0uU1AgubTWJo0LZbEDTPY-zRSxxaCAtHE/' #@param {type:\"string\"}\n",
        "output_ws = 'testing'\n",
        "output_row = 2\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhzZStW-9IKI"
      },
      "source": [
        "#maia\n",
        "maia_url = 'https://docs.google.com/spreadsheets/d/1zit8jJhj7ccbX9P4iiXaW3Fxs5ITrEaZ6UZCw9isEAQ/'            #id of spreadsheet with list of objects (now MAIA)\n",
        "maia_ws = 'DB_KeyProd'                    #worksheet with products\n",
        "maia_row = 5\n",
        "\n",
        "wb1 = gc.open_by_url(maia_url)\n",
        "sh1 = wb1.worksheet(maia_ws)\n",
        "maia_df = pd.DataFrame(sh1.get_all_values(),columns=sh1.row_values(maia_row)).iloc[maia_row:].reset_index(drop=True)\n",
        "\n",
        "#make df with key products, keywords\n",
        "df_key = maia_df[[\"Key Product\", \"Keywords\", \"Category\"]].reset_index(drop=True)\n",
        "df_key.columns = ['key_product','keywords', 'keyword_count', 'maia_category']\n",
        "df_key = df_key.drop(['keyword_count'], axis=1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-BBsmZmBKd-"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVs3t3kopnZO"
      },
      "source": [
        "## Scrapers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rVlIRydNdPI"
      },
      "source": [
        "def bol_cat(prod):\n",
        "  start = time.time()\n",
        "  s = time.time()\n",
        "  URL = \"https://www.bol.com/nl/s/?searchtext=\"+prod+\"&searchContext=media_all&appliedSearchContextId=media_all&suggestFragment=&adjustedSection=&originalSection=&originalSearchContext=&section=main&N=0&defaultSearchContext=media_all\"\n",
        "  response = requests.get(URL)\n",
        "  e = time.time()\n",
        "  # print(e-s)\n",
        "  s = time.time()\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  e = time.time()\n",
        "  # print(e-s)\n",
        "\n",
        "  try:\n",
        "    s = time.time()\n",
        "    # find url extension (href) of first product in search results\n",
        "    soup = soup.find('div',{'class':'product-item__info hit-area'})\n",
        "    alist = soup.findAll('a')[1]\n",
        "    href = alist['href']\n",
        "    e = time.time()\n",
        "    # print(e-s)\n",
        "\n",
        "\n",
        "    s = time.time()\n",
        "    # open page of first product\n",
        "    URL = 'https://www.bol.com'+href\n",
        "    response = requests.get(URL)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    e = time.time()\n",
        "    # print(e-s)\n",
        "\n",
        "    soup = soup.findAll('li', {'class':'breadcrumbs__item'})\n",
        "    s4 = str(soup[2].find('a'))\n",
        "    s5 = str(soup[3].find('a'))\n",
        "\n",
        "    # this is bad:\n",
        "    # get categories\n",
        "    s = time.time()\n",
        "    s4 = s4[s4.find('name\">')+6:s4.find('</span>')]\n",
        "    s5 = s5[s5.find('name\">')+6:s5.find('</span>')]\n",
        "    e = time.time()\n",
        "    # print(e-s)\n",
        "    # convert categories to single string\n",
        "    cat = s4+' // '+s5+' // '\n",
        "  except:\n",
        "    cat = 'Unknown'\n",
        "  end = time.time()\n",
        "  # print(end-start)\n",
        "  return cat\n",
        "\n",
        "def cb_cat(prod):\n",
        "  URL = \"https://www.coolblue.nl/zoeken?query=\"+prod\n",
        "  response = requests.get(URL)\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  try:\n",
        "    # find url extension (href) of first product in search results\n",
        "    soup = soup.find('div',{'class':'product-grid__card'})\n",
        "    alist = soup.findAll('a')[1]\n",
        "    href = alist['href']\n",
        "\n",
        "    # open page of first product\n",
        "    URL = 'https://www.coolblue.nl'+href\n",
        "    response = requests.get(URL)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    \n",
        "    # get categories\n",
        "    soup = soup.findAll('ol', {'class':'breadcrumbs is-visible breadcrumbs--has-bottom-spacing'})\n",
        "    alist = soup[0].findAll('a', {'class':'link'})\n",
        "    # convert categories to single string\n",
        "    cat = ''\n",
        "    for i in alist[1:]:\n",
        "      cat = cat + i['title'] + ' // '\n",
        "  except:\n",
        "    cat = 'Unknown'\n",
        "  return cat\n",
        "\n",
        "def ah_cat(prod):\n",
        "  URL = \"https://www.ah.nl/zoeken?query=\"+prod\n",
        "  response = requests.get(URL)\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  try:\n",
        "    # find url extension (href) of first product in search result\n",
        "    soup = soup.find('div',{'class':'product-card-portrait_content__KKpmv'})\n",
        "    alist = soup.findAll('a')\n",
        "    href = alist[0]['href']\n",
        "    # open page of first product\n",
        "    URL = 'https://www.ah.nl'+href\n",
        "    response = requests.get(URL)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    # get categories\n",
        "    soup = soup.findAll('ol', {'class':'breadcrumbs_list__1g8sQ page-navigation_breadcrumbs__22sFV'})\n",
        "    s3 = soup[0].findAll('a', {'class':'breadcrumbs_link__2Edfx'})\n",
        "    cat = ''\n",
        "    # convert categories to single string\n",
        "    for i in range(len(s3[2:])):\n",
        "      cat = cat+s3[i+2]['title']+' // '\n",
        "  except:\n",
        "    cat = 'Unknown'\n",
        "  return cat\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-pmfCkMpt13"
      },
      "source": [
        "## Apply's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "475by86Q5p0c"
      },
      "source": [
        "def bol_apply(x):\n",
        "  search = x['key_product']\n",
        "  search = tr.translate(search, dest='nl').text\n",
        "  search = search.replace(' ', '+')\n",
        "  x['bol_category'] = bol_cat(search)\n",
        "  return x\n",
        "\n",
        "def cb_apply(x):\n",
        "  search = x['key_product'].replace(' ', '+')\n",
        "  if x['maia_category'] == 'ICT':\n",
        "    x['cb_category'] = cb_cat(x['key_product'])\n",
        "  else:\n",
        "    x['cb_category'] = ' '\n",
        "  return x\n",
        "\n",
        "def ah_apply(x):\n",
        "  search = x['key_product']\n",
        "  search = tr.translate(search, dest='nl').text\n",
        "  search = x['key_product'].replace(' ', '%20')\n",
        "  if x['maia_category'] == 'Food':\n",
        "    x['ah_category'] = ah_cat(x['key_product'])\n",
        "  elif x['maia_category'] == 'Drinks':\n",
        "    x['ah_category'] = ah_cat(x['key_product'])\n",
        "  else:\n",
        "    x['ah_category'] = ' '\n",
        "  return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWfuPXkNp9I9"
      },
      "source": [
        "## Write to spreadsheet function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9grNGWCiqAry"
      },
      "source": [
        "def output_to_ws(data, column, ws, row):\n",
        "  #data: df column\n",
        "  #column: string of column index; 'A', 'B', 'C' etc.\n",
        "  #ws: worksheet of interest\n",
        "  \n",
        "  cell_list = ws.range(column+str(row)+':'+column+str(len(data)+row-1))\n",
        "  for i in range(len(cell_list)):\n",
        "    try:\n",
        "      cell_list[i].value = float(data[i])\n",
        "    except:\n",
        "      cell_list[i].value = data[i]\n",
        "  ws.update_cells(cell_list)\n",
        "  return column"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJN6gAv-p0Yd"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojUkzmL-q6X8",
        "outputId": "e9a80b0b-739f-4bde-960e-a8c41665da08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# bol guesses\n",
        "start = time.time()\n",
        "# df_key = df_key.apply(bol_apply, axis=1)\n",
        "df_key = df_key.parallel_apply(bol_apply, axis=1)\n",
        "end = time.time()\n",
        "print(\"Bol time: %s sec\" % round(end-start, 2))\n",
        "\n",
        "# coolblue guesses\n",
        "start = time.time()\n",
        "# df_key = df_key.apply(cb_apply, axis=1)\n",
        "df_key = df_key.parallel_apply(cb_apply, axis=1)\n",
        "end = time.time()\n",
        "print(\"Coolblue time: %s sec\" % round(end-start, 2))\n",
        "\n",
        "# albert heijn guesses\n",
        "start = time.time()\n",
        "# df_key = df_key.apply(ah_apply, axis=1)\n",
        "df_key = df_key.parallel_apply(ah_apply, axis=1)\n",
        "end = time.time()\n",
        "print(\"Albert Heijn time: %s sec\" % round(end-start, 2))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bol time: 11.25 sec\n",
            "Coolblue time: 0.1 sec\n",
            "Albert Heijn time: 13.99 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGRrGp2LAz6z"
      },
      "source": [
        "# write to spreadsheet\n",
        "#output column names\n",
        "cols = ['A', 'B', 'C', 'D', 'E', 'F']\n",
        "#columns of data to output\n",
        "datasets = [df_key['key_product'], df_key['keywords'], df_key['maia_category'], df_key['bol_category'], df_key['cb_category'], df_key['ah_category']]\n",
        "output_ws = gc.open_by_url(output_url).worksheet(output_ws)\n",
        "for i in range(len(datasets)):\n",
        "  output_to_ws(datasets[i], cols[i], output_ws, output_row)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "726UU-9tqbl5"
      },
      "source": [
        "# Archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwTkMBujY1H4"
      },
      "source": [
        "import requests\n",
        "import urllib.request\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#input url of search page for product\n",
        "prod = 'chocolate'\n",
        "url = 'https://www.walmart.com/search/?query='+prod\n",
        "response = requests.get(url)\n",
        "print(response)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "print(soup)\n",
        "soup = soup.find('div',{'class':'search-product-result'})\n",
        "print(soup)\n",
        "alist = soup.findAll('a')\n",
        "\n",
        "def get_name(href):\n",
        "    url = 'https://www.walmart.com/'+href\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    soup = soup.find('h1',{'class':'prod-ProductTitle prod-productTitle-buyBox font-bold'})\n",
        "    return soup['content']\n",
        "\n",
        "laptops=[]\n",
        "\n",
        "for i in range(len(alist)):\n",
        "    laptops.append(get_name(alist[i]['href']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFwe3Jgxa-3w"
      },
      "source": [
        "!pip install -U selenium\n",
        "\n",
        "from selenium import webdriver as driver\n",
        "\n",
        "browser = driver.PhantomJS()\n",
        "p = browser.get(\"http://en.wikipedia.org/wiki/StackOverflow\")\n",
        "assert \"Stack Overflow - Wikipedia\" in browser.title"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}